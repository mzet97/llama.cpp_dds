"""
  Generated by Eclipse Cyclone DDS idlc Python Backend
  Cyclone DDS IDL version: v11.0.0
  Module: llama
  IDL file: LlamaDDS.idl

"""

from dataclasses import dataclass
from enum import auto
from typing import TYPE_CHECKING, Optional

import cyclonedds.idl as idl
import cyclonedds.idl.annotations as annotate
import cyclonedds.idl.types as types

# root module import for resolving types
import llama


@dataclass
@annotate.final
@annotate.autoid("sequential")
class ChatMessage(idl.IdlStruct, typename="llama.ChatMessage"):
    role: str
    content: str


@dataclass
@annotate.final
@annotate.autoid("sequential")
class ChatCompletionRequest(idl.IdlStruct, typename="llama.ChatCompletionRequest"):
    request_id: str
    model: str
    messages: types.sequence['llama.ChatMessage']
    temperature: types.float32
    max_tokens: types.int32
    stream: bool
    top_p: types.sequence[types.float32]
    n: types.sequence[types.int32]
    stop: types.sequence[str]


@dataclass
@annotate.final
@annotate.autoid("sequential")
class ChatCompletionResponse(idl.IdlStruct, typename="llama.ChatCompletionResponse"):
    request_id: str
    model: str
    content: str
    finish_reason: str
    is_final: bool
    prompt_tokens: types.int32
    completion_tokens: types.int32


@dataclass
@annotate.final
@annotate.autoid("sequential")
class ServerStatus(idl.IdlStruct, typename="llama.ServerStatus"):
    server_id: str
    slots_idle: types.int32
    slots_processing: types.int32
    model_loaded: str
    ready: bool


@dataclass
@annotate.final
@annotate.autoid("sequential")
class EmbeddingRequest(idl.IdlStruct, typename="llama.EmbeddingRequest"):
    request_id: str
    model: str
    input: str


@dataclass
@annotate.final
@annotate.autoid("sequential")
class EmbeddingResponse(idl.IdlStruct, typename="llama.EmbeddingResponse"):
    request_id: str
    model: str
    embedding: types.sequence[types.float32]
    tokens: types.int32


